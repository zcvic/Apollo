name: "darknet-16c-16x-3d multitask TEST 960x384, offset L3:440, L4: 312, RM DET"

layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 768
      dim: 768
      dim: 3
    }
  }
}
layer {
  name: "data_perm"
  type: "Permute"
  bottom: "data"
  top: "data_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}

layer{
  name: "scale_data_lane"
  type: "Power"
  bottom: "data_perm"
  top: "scale_data_lane"
  power_param {
      power: 1
      scale: 0.00392157
      shift: 0
  }
  propagate_down: false

}

##### end lane data layer ####

##########################################################

layer {
  name: "conv1"
  type: "Convolution"
  bottom: "scale_data_lane"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv1_bn"
  type: "BatchNorm"
  bottom: "conv1"
  top: "conv1"

  batch_norm_param {    
    eps: 1e-06
  }
}
layer {
  name: "conv1_scale"
  type: "Scale"
  bottom: "conv1"
  top: "conv1"
  param {                                                                                                                                                                                     lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    pad: 0
    stride: 2
  }
}

layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv2_bn"
  type: "BatchNorm"
  bottom: "conv2"
  top: "conv2"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv2_scale"
  type: "Scale"
  bottom: "conv2"
  top: "conv2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv2_relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    pad: 0
    stride: 2
  }
}

layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_1_bn"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
 
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv3_1_scale"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_2_bn"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
 
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv3_2_scale"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv3_3_bn"
  type: "BatchNorm"
  bottom: "conv3_3"
  top: "conv3_3"
 
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv3_3_scale"
  type: "Scale"
  bottom: "conv3_3"
  top: "conv3_3"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    pad: 0
    stride: 2
  }
}

layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_1_bn"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv4_1_scale"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_2_bn"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv4_2_scale"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv4_3_bn"
  type: "BatchNorm"
  bottom: "conv4_3"
  top: "conv4_3"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv4_3_scale"
  type: "Scale"
  bottom: "conv4_3"
  top: "conv4_3"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv4_3_relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    pad: 0
    stride: 2
  }
}

layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_1_bn"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv5_1_scale"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_2_bn"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
 
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv5_2_scale"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv5_2_relu"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_3_bn"
  type: "BatchNorm"
  bottom: "conv5_3"
  top: "conv5_3"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv5_3_scale"
  type: "Scale"
  bottom: "conv5_3"
  top: "conv5_3"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv5_3_relu"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_4_bn"
  type: "BatchNorm"
  bottom: "conv5_4"
  top: "conv5_4"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv5_4_scale"
  type: "Scale"
  bottom: "conv5_4"
  top: "conv5_4"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv5_4_relu"
  type: "ReLU"
  bottom: "conv5_4"
  top: "conv5_4"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "conv5_4"
  top: "conv5_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv5_5_bn"
  type: "BatchNorm"
  bottom: "conv5_5"
  top: "conv5_5"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv5_5_scale"
  type: "Scale"
  bottom: "conv5_5"
  top: "conv5_5"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv5_5_relu"
  type: "ReLU"
  bottom: "conv5_5"
  top: "conv5_5"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    pad: 1
    stride: 1
  }
}

layer {
  name: "conv6_1"
  type: "Convolution"
  bottom: "pool5"
  top: "conv6_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 2
    kernel_size: 3
    dilation: 2
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_1_bn"
  type: "BatchNorm"
  bottom: "conv6_1"
  top: "conv6_1"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv6_1_scale"
  type: "Scale"
  bottom: "conv6_1"
  top: "conv6_1"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_2_bn"
  type: "BatchNorm"
  bottom: "conv6_2"
  top: "conv6_2"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv6_2_scale"
  type: "Scale"
  bottom: "conv6_2"
  top: "conv6_2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_3_bn"
  type: "BatchNorm"
  bottom: "conv6_3"
  top: "conv6_3"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv6_3_scale"
  type: "Scale"
  bottom: "conv6_3"
  top: "conv6_3"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv6_3_relu"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv6_4"
  type: "Convolution"
  bottom: "conv6_3"
  top: "conv6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_4_bn"
  type: "BatchNorm"
  bottom: "conv6_4"
  top: "conv6_4"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv6_4_scale"
  type: "Scale"
  bottom: "conv6_4"
  top: "conv6_4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv6_4_relu"
  type: "ReLU"
  bottom: "conv6_4"
  top: "conv6_4"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv6_5"
  type: "Convolution"
  bottom: "conv6_4"
  top: "conv6_5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv6_5_bn"
  type: "BatchNorm"
  bottom: "conv6_5"
  top: "conv6_5"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv6_5_scale"
  type: "Scale"
  bottom: "conv6_5"
  top: "conv6_5"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv6_5_relu"
  type: "ReLU"
  bottom: "conv6_5"
  top: "conv6_5"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_5"
  top: "conv7_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_1_bn"
  type: "BatchNorm"
  bottom: "conv7_1"
  top: "conv7_1"
 
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv7_1_scale"
  type: "Scale"
  bottom: "conv7_1"
  top: "conv7_1"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: false
    pad: 1
    kernel_size: 3
    dilation: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "conv7_2_bn"
  type: "BatchNorm"
  bottom: "conv7_2"
  top: "conv7_2"
  
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "conv7_2_scale"
  type: "Scale"
  bottom: "conv7_2"
  top: "conv7_2"
  param {                                                                                                                                                                                      
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
  relu_param {
    negative_slope: 0.0
  }
}

layer {
  name: "concat8"
  type: "Concat"
  bottom: "conv5_5"
  bottom: "conv7_2"
  top: "concat8"
  concat_param {
    axis: 1
  }
}


############## slice blob according to batch size ##############

############## Parsing ###############################
######### upsample 1 ########
layer {
  name: "reduce1_lane"
  type: "Convolution"
  bottom: "concat8"
  top: "reduce1_lane"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "reduce1_lane_bn"
  type: "BatchNorm"
  bottom: "reduce1_lane"
  top: "reduce1_lane"

  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "reduce1_lane_scale"
  type: "Scale"
  bottom: "reduce1_lane"
  top: "reduce1_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "reduce1_lane_relu"
  type: "ReLU"
  bottom: "reduce1_lane"
  top: "reduce1_lane"
  relu_param {
    negative_slope: 0
  }
}

layer {
    name: "deconv1_lane"
    type: "Deconvolution"
    bottom: "reduce1_lane"
    top: "deconv1_lane"
    param{
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
      kernel_size: 2  # {{2 * factor _ factor % 2}}  2 * 2 _ 0
      stride: 2       # {{factor}}
      num_output: 64 # {{C}} 
      #group: 48      # {{C}}
      pad: 0          # {{ceil((factor _ 1) / 2.)}} 2 _ 1 / 2
      weight_filler: { type: "xavier" } 
      bias_filler {
          type: "constant"
          value: 0
      }
    }
}

layer {
  name: "deconv1_lane_bn"
  type: "BatchNorm"
  bottom: "deconv1_lane"
  top: "deconv1_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "deconv1_lane_scale"
  type: "Scale"
  bottom: "deconv1_lane"
  top: "deconv1_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "deconv1_lane_relu"
  type: "ReLU"
  bottom: "deconv1_lane"
  top: "deconv1_lane"
  relu_param {
    negative_slope: 0
  }
}
########## end upsample 1 #####

######### upsample 2 ########

layer {
  name: "reorg4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "reorg4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
##layer {
## name: "reorg4_bn"
## type: "BatchNorm"
## bottom: "reorg4"
## top: "reorg4"
## batch_norm_param {
##   eps: 1e-06
## }
##}
##layer {
## name: "reorg4_scale"
## type: "Scale"
## bottom: "reorg4"
## top: "reorg4"
## scale_param {
##   filler {
##     type: "constant"
##     value: 1
##   }
##   bias_term: true
## }
##}
layer {
  name: "reorg4_relu"
  type: "ReLU"
  bottom: "reorg4"
  top: "reorg4"
  relu_param {
    negative_slope: 0
  }
}

layer {
    type: "Concat"
    name: "concat4"
    bottom: "reorg4"
    bottom: "deconv1_lane"
    top: "concat4"

    concat_param{
      axis: 1
    }  
}


layer {
  name: "reduce2_lane"
  type: "Convolution"
  bottom: "concat4"
  top: "reduce2_lane"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "reduce2_lane_bn"
  type: "BatchNorm"
  bottom: "reduce2_lane"
  top: "reduce2_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "reduce2_lane_scale"
  type: "Scale"
  bottom: "reduce2_lane"
  top: "reduce2_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "reduce2_lane_relu"
  type: "ReLU"
  bottom: "reduce2_lane"
  top: "reduce2_lane"
  relu_param {
    negative_slope: 0
  }
}

layer {
    name: "deconv2_lane"
    type: "Deconvolution"
    bottom: "reduce2_lane"
    top: "deconv2_lane"
    param{
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
      kernel_size: 2  # {{2 * factor _ factor % 2}}  2 * 2 _ 0
      stride: 2       # {{factor}}
      num_output: 32 # {{C}} 
      #group: 48      # {{C}}
      pad: 0          # {{ceil((factor _ 1) / 2.)}} 2 _ 1 / 2
      weight_filler: { type: "xavier" } 
      bias_filler {
          type: "constant"
          value: 0
      }
    }
}

layer {
  name: "deconv2_lane_bn"
  type: "BatchNorm"
  bottom: "deconv2_lane"
  top: "deconv2_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "deconv2_lane_scale"
  type: "Scale"
  bottom: "deconv2_lane"
  top: "deconv2_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "deconv2_lane_relu"
  type: "ReLU"
  bottom: "deconv2_lane"
  top: "deconv2_lane"
  relu_param {
    negative_slope: 0
  }
}


########## end upsample 2 #####

########### upsample 3

layer {
  name: "reorg3"
  type: "Convolution"
  bottom: "conv3_3"
  top: "reorg3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
##layer {
## name: "reorg3_bn"
## type: "BatchNorm"
## bottom: "reorg3"
## top: "reorg3"
## batch_norm_param {
##   eps: 1e-06
## }
##}
##layer {
## name: "reorg3_scale"
## type: "Scale"
## bottom: "reorg3"
## top: "reorg3"
## scale_param {
##   filler {
##     type: "constant"
##     value: 1
##   }
##   bias_term: true
## }
##}
layer {
  name: "reorg3_relu"
  type: "ReLU"
  bottom: "reorg3"
  top: "reorg3"
  relu_param {
    negative_slope: 0
  }
}


layer {
    type: "Concat"
    name: "concat3"
    bottom: "reorg3"
    bottom: "deconv2_lane"
    top: "concat3"

    concat_param{
      axis: 1
    }  
}

layer {
  name: "reduce3_lane"
  type: "Convolution"
  bottom: "concat3"
  top: "reduce3_lane"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "reduce3_lane_bn"
  type: "BatchNorm"
  bottom: "reduce3_lane"
  top: "reduce3_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "reduce3_lane_scale"
  type: "Scale"
  bottom: "reduce3_lane"
  top: "reduce3_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "reduce3_lane_relu"
  type: "ReLU"
  bottom: "reduce3_lane"
  top: "reduce3_lane"
  relu_param {
    negative_slope: 0
  }
}
layer {
    name: "deconv3_lane"
    type: "Deconvolution"
    bottom: "reduce3_lane"
    top: "deconv3_lane"
    param{
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
      kernel_size: 2  # {{2 * factor _ factor % 2}}  2 * 2 _ 0
      stride: 2       # {{factor}}
      num_output: 16 # {{C}} 
      #group: 48      # {{C}}
      pad: 0          # {{ceil((factor _ 1) / 2.)}} 2 _ 1 / 2
      weight_filler: { type: "xavier" } 
      bias_filler {
          type: "constant"
          value: 0
      }
    }
}

layer {
  name: "deconv3_lane_bn"
  type: "BatchNorm"
  bottom: "deconv3_lane"
  top: "deconv3_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "deconv3_lane_scale"
  type: "Scale"
  bottom: "deconv3_lane"
  top: "deconv3_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "deconv3_lane_relu"
  type: "ReLU"
  bottom: "deconv3_lane"
  top: "deconv3_lane"
  relu_param {
    negative_slope: 0
  }
}


########## end upsample 3 #####

######### upsample 4 ########

 layer {
  name: "reorg2"
  type: "Convolution"
  bottom: "conv2"
  top: "reorg2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
 }
#layer {
# name: "reorg2_bn"
# type: "BatchNorm"
# bottom: "reorg2"
# top: "reorg2"
# batch_norm_param {
#   eps: 1e-06
# }
#}
#layer {
# name: "reorg2_scale"
# type: "Scale"
# bottom: "reorg2"
# top: "reorg2"
# scale_param {
#   filler {
#     type: "constant"
#     value: 1
#   }
#   bias_term: true
# }
#}
layer {
  name: "reorg2_relu"
  type: "ReLU"
  bottom: "reorg2"
  top: "reorg2"
  relu_param {
    negative_slope: 0
  }
}


layer {
  name: "concat2"
  type: "Concat"
  bottom: "reorg2"
  bottom: "deconv3_lane"
  top: "concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce4_lane"
  type: "Convolution"
  bottom: "concat2"
  top: "reduce4_lane"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "reduce4_lane_bn"
  type: "BatchNorm"
  bottom: "reduce4_lane"
  top: "reduce4_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "reduce4_lane_scale"
  type: "Scale"
  bottom: "reduce4_lane"
  top: "reduce4_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "reduce4_lane_relu"
  type: "ReLU"
  bottom: "reduce4_lane"
  top: "reduce4_lane"
  relu_param {
    negative_slope: 0
  }
}

layer {
    name: "deconv4_lane"
    type: "Deconvolution"
    bottom: "reduce4_lane"
    top: "deconv4_lane"
    param{
        lr_mult: 1
        decay_mult: 1
    }
    convolution_param {
      kernel_size: 2  # {{2 * factor _ factor % 2}}  2 * 2 _ 0
      stride: 2       # {{factor}}
      num_output: 8 # {{C}} 
      #group: 48      # {{C}}
      pad: 0          # {{ceil((factor _ 1) / 2.)}} 2 _ 1 / 2
      weight_filler: { type: "xavier" } 
      bias_filler {
          type: "constant"
          value: 0
      }
    }
}
layer {
  name: "deconv4_lane_bn"
  type: "BatchNorm"
  bottom: "deconv4_lane"
  top: "deconv4_lane"
  batch_norm_param {
    
    eps: 1e-06
  }
}
layer {
  name: "deconv4_lane_scale"
  type: "Scale"
  bottom: "deconv4_lane"
  top: "deconv4_lane"
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
  }
}
layer {
  name: "deconv4_lane_relu"
  type: "ReLU"
  bottom: "deconv4_lane"
  top: "deconv4_lane"
  relu_param {
    negative_slope: 0
  }
}

layer {
  name: "reorg1"
  type: "Convolution"
  bottom: "conv1"
  top: "reorg1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 8
    bias_term: false
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
#layer {
# name: "reorg1_bn"
# type: "BatchNorm"
# bottom: "reorg1"
# top: "reorg1"
# batch_norm_param {
#   eps: 1e-06
# }
#}
#layer {
# name: "reorg1_scale"
# type: "Scale"
# bottom: "reorg1"
# top: "reorg1"
# scale_param {
#   filler {
#     type: "constant"
#     value: 1
#   }
#   bias_term: true
# }
#}
layer {
  name: "reorg1_relu"
  type: "ReLU"
  bottom: "reorg1"
  top: "reorg1"
  relu_param {
    negative_slope: 0
  }
}


layer {
  name: "concat1"
  type: "Concat"
  bottom: "reorg1"
  bottom: "deconv4_lane"
  top: "concat1"
  concat_param {
    axis: 1
  }
}

layer {
  name: "conv_out"
  type: "Convolution"
  bottom: "concat1"
  top: "conv_out"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}



layer {
  name: "softmax"
  type: "Softmax"
  bottom: "conv_out"
  top: "softmax"
}

########## end upsample 4 #####




